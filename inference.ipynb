{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f8b490-bdbf-463a-9d2d-bf4669e0d41f",
   "metadata": {},
   "source": [
    "# Welcome to RAD-MMM inference tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c24bb3-4937-4068-bb1e-f7f6efd00370",
   "metadata": {},
   "source": [
    "Before we begin, please download the following dependencies:\n",
    "\n",
    "1. Language dictionaries from [here](https://drive.google.com/drive/folders/1woNCODwXh9aHu7Fd6b4Jo42aL7f5RFZg) and place them in `RAD-MMM/assets` folder.\n",
    "2. Download RAD-MMM checkpoint and its config - [radmmm_converged_decoder_attribute_predictors.ckpt](https://drive.google.com/file/d/1p8SEVHRlyLQpQnVP2Dc66RlqJVVRDCsJ/view), and [config.yaml](https://drive.google.com/file/d/1zOt9cQM9NqKFZFQ1N06gQpR10LFwtvQd/view).\n",
    "3. Download HiFi-GAN vocoder checkpoint and its config - [g_00072000](https://drive.google.com/file/d/1VaH5_MhAjAjHlihi2k-lcOOoy4NqtRV4/view) and [config_16khz.json](https://drive.google.com/file/d/1-eBTNfIh-LSstNirQawHW4jsI-t01jTU/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "! pip install jsonargparse\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "import re\n",
    "import yaml\n",
    "sys.path.append('vocoders')\n",
    "from pytorch_lightning.cli import LightningCLI\n",
    "from tts_lightning_modules import TTSModel\n",
    "from data_modules import BaseAudioDataModule\n",
    "from jsonargparse import lazy_instance\n",
    "from decoders import RADMMMFlow\n",
    "from loss import RADTTSLoss\n",
    "import inspect\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from training_callbacks import LogDecoderSamplesCallback, \\\n",
    "    LogAttributeSamplesCallback\n",
    "from utils import get_class_args\n",
    "from tts_text_processing.text_processing import TextProcessing\n",
    "from common import Encoder\n",
    "import torch\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo: Set paths for downloaded files\n",
    "radmmm_model_path = \"/path/to/radmmm_converged_decoder_attribute_predictors.ckpt\"\n",
    "gen_config_path = \"/path/to/config.yaml\"\n",
    "voc_model_path = \"/path/to/g_00072000\"\n",
    "voc_config_path = \"/path/to/config_16khz.json\"\n",
    "phonemizer_cfg='{\"en_US\": \"assets/en_US_word_ipa_map.txt\",\"es_MX\": \"assets/es_MX_word_ipa_map.txt\",\"de_DE\": \"assets/de_DE_word_ipa_map.txt\",\"en_UK\": \"assets/en_UK_word_ipa_map.txt\",\"es_CO\": \"assets/es_CO_word_ipa_map.txt\",\"es_ES\": \"assets/es_ES_word_ipa_map.txt\",\"fr_FR\": \"assets/fr_FR_word_ipa_map.txt\",\"hi_HI\": \"assets/hi_HI_word_ipa_map.txt\",\"pt_BR\": \"assets/pt_BR_word_ipa_map.txt\",\"te_TE\": \"assets/te_TE_word_ipa_map.txt\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb91da-18c9-4014-933b-41d4e9278c5c",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edddca9-4d40-456e-9a80-cc438859255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config\n",
    "\n",
    "with open(gen_config_path, \"r\") as f:\n",
    "    gen_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86dbb4-be11-412b-979b-ad13ec9e52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_class(init):\n",
    "    \"\"\"Instantiates a class with the given args and init.\n",
    "\n",
    "    Args:\n",
    "        args: Positional arguments required for instantiation.\n",
    "        init: Dict of the form {\"class_path\":...,\"init_args\":...}.\n",
    "\n",
    "    Returns:\n",
    "        The instantiated class object.\n",
    "    \"\"\"\n",
    "    kwargs = init.get(\"init_args\", {})\n",
    "    class_module, class_name = init[\"class_path\"].rsplit(\".\", 1)\n",
    "    module = __import__(class_module, fromlist=[class_name])\n",
    "    args_class = getattr(module, class_name)\n",
    "    return args_class(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c16de-ca51-423f-a718-0a17ea93884b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate submodules\n",
    "\n",
    "gen_config[\"model\"][\"add_bos_eos_to_text\"] = False\n",
    "gen_config[\"model\"][\"append_space_to_text\"] = True\n",
    "gen_config[\"model\"][\"decoder_path\"] = radmmm_model_path\n",
    "gen_config[\"model\"][\"encoders_path\"] = radmmm_model_path\n",
    "gen_config[\"model\"][\"handle_phoneme\"] = \"word\"\n",
    "gen_config[\"model\"][\"handle_phoneme_ambiguous\"] = \"ignore\"\n",
    "gen_config[\"model\"][\"heteronyms_path\"] = \"tts_text_processing/heteronyms\"\n",
    "gen_config[\"model\"][\"output_directory\"] = \"tutorials/run1\"\n",
    "gen_config[\"model\"][\"p_phoneme\"] = 1\n",
    "gen_config[\"model\"][\"phoneme_dict_path\"] = \"tts_text_processing/cmudict-0.7b\"\n",
    "gen_config[\"model\"][\"phonemizer_cfg\"] = phonemizer_cfg\n",
    "gen_config[\"model\"][\"prediction_output_dir\"] = \"tutorials/out1\"\n",
    "gen_config[\"model\"][\"prepend_space_to_text\"] = True\n",
    "gen_config[\"model\"][\"sampling_rate\"] = 16000\n",
    "gen_config[\"model\"][\"symbol_set\"] = \"radmmm_phonemizer_marker_segregated\"\n",
    "gen_config[\"model\"][\"vocoder_checkpoint_path\"] = voc_model_path\n",
    "gen_config[\"model\"][\"vocoder_config_path\"] = voc_config_path\n",
    "\n",
    "hparams = gen_config[\"model\"]\n",
    "ttsmodel_kwargs={}\n",
    "for k,v in hparams.items():\n",
    "    if type(v) == dict and 'class_path' in v:\n",
    "        print(k)\n",
    "        ttsmodel_kwargs[k] = instantiate_class(v)\n",
    "    elif k != \"_instantiator\":\n",
    "        ttsmodel_kwargs[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c366d31-416e-4346-8589-0db6c8cfa2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the model from checkpoint\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TTSModel.load_from_checkpoint(checkpoint_path=radmmm_model_path,\\\n",
    "                                      **ttsmodel_kwargs).to(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dba2b0-0b78-4207-ba83-bd8914290850",
   "metadata": {},
   "source": [
    "## Initialize the datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bd7b8-01da-4c68-b214-2781a375033a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the datamodule\n",
    "\n",
    "gen_config[\"data\"][\"batch_size\"]=1\n",
    "gen_config[\"data\"][\"phonemizer_cfg\"]=phonemizer_cfg\n",
    "gen_config[\"data\"][\"inference_transcript\"] = None \n",
    "data_module = BaseAudioDataModule(**gen_config['data'])\n",
    "data_module.setup(stage = \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7354be9-16b2-42d1-9603-efea292fc54c",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b11c0a-4507-4cda-a6d1-3538cba7f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the input through the model\n",
    "def run_inference(script, speaker_id, input_language_id, target_accent_id):\n",
    "    \n",
    "    inferData = [{\n",
    "      \"script\": script,\n",
    "      \"spk_id\": speaker_id,\n",
    "      \"decoder_spk_id\": speaker_id,\n",
    "      \"duration_spk_id\": speaker_id,\n",
    "      \"energy_spk_id\": speaker_id,\n",
    "      \"f0_spk_id\": speaker_id,\n",
    "      \"language\": target_accent_id,\n",
    "      \"emotion\": \"other\"\n",
    "    }]\n",
    "    \n",
    "    ## set predictset\n",
    "    data_module.predictset.data = inferData\n",
    "    \n",
    "    ## initialize and get the dataloader\n",
    "    dl = data_module.predict_dataloader()\n",
    "    \n",
    "    ## get the first input\n",
    "    inp = next(iter(dl))\n",
    "    \n",
    "    ## move the input tensors to GPU\n",
    "    for k in inp.keys():\n",
    "        if type(inp[k]) == torch.Tensor:\n",
    "            inp[k] = inp[k].to(device=device)\n",
    "\n",
    "    return model.forward(inp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de526e66",
   "metadata": {},
   "source": [
    "## Text Processing: Conversion to Phonemes Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516a5f3-0ab1-4da8-bad0-5b40fbbb12de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first example - Converting hindi text to phonemes\n",
    "\n",
    "text = \"आशा है कि आप अब तक हमारे सत्र का आनंद ले रहे हैं!\"\n",
    "speaker_id = \"indic-iiit-hyd-female\"\n",
    "input_language_id = \"hi_HI\"\n",
    "\n",
    "print(\"Input Sentence: \", text)\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fdadc-ebfe-475e-9b55-0b28889c3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first example - showing word to phoneme mapping\n",
    "\n",
    "_words_re = re.compile(r\"([a-zA-Z\\u0900-\\u097F]+['][a-zA-Z\\u0900-\\u097F]+|[a-zA-Z\\u0900-\\u097F]+)\")\n",
    "\n",
    "phonemes = script.split(\"} {\")\n",
    "\n",
    "words = _words_re.findall(text)\n",
    "\n",
    "print(\"word\\t--->\\tphoneme\")\n",
    "for t,p in zip(words, phonemes):\n",
    "    if \"{\" in p:\n",
    "        p = p[1:]\n",
    "    elif \"}\" in p:\n",
    "        p = p[:-1]\n",
    "    print(t, \"\\t--->\\t\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac190782-5361-4b64-96df-829fd00b13c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Continuing first example - native hindi speaker speaking hindi\n",
    "# you can also specify phonemes directly for fine-grained control\n",
    "\n",
    "script = \"{ˈaː ʃ aː} {h ɛː} {k ˈɪ} {ˌaː p} {ˈʌ b} {t ˌə k} {h ə m ˌaː ɾ eː} {s ˈʌ t ɾ ə} {k aː} {aː n ˈʌ n d} {l ˈeː} {ɾ ˌə h eː} {h ɛ̃!}\"\n",
    "\n",
    "# running the inference\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29737eb-62a6-46de-ab55-419c856df113",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decff5a5",
   "metadata": {},
   "source": [
    "## Hindi-Native Speaker Speaking English in English Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720f360-267e-466e-81fc-925f16027a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second example - native hindi speaker speaking english in english accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"indic-iiit-hyd-female\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = input_language_id\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{h ˈoʊ p} {j uː} {ɑː ɹ} {ɛ n dʒ ˈɔɪ ɪ ŋ} {ˌaʊ ɚ} {s ˈɛ ʃ ə n} {s ˈoʊ} {f ˌɑːɹ!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b812b-c037-46a1-8b5a-fdb4273dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5eb2ad",
   "metadata": {},
   "source": [
    "## Hindi-Native Speaker Speaking English in Hindi Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0dca5-fdd5-4a4f-92ab-504a1ce61038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# third example - native hindi speaker speaking english in hindi accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"indic-iiit-hyd-female\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"hi_HI\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{(en) h ˈəʊ p} {j uː} {ɑː ɹ} {ɛ n dʒ ˈɔɪ ɪ ŋ} {ˌaʊ ə} {s ˈɛ ʃ ə n} {s ˈəʊ} {f ˌɑː (hi)!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcdaa1f-f197-4071-a539-9871c98dc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4de499",
   "metadata": {},
   "source": [
    "## German-Native Speaker Speaking English in German Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9edae-1f2a-464d-b0c4-2f7f340b5c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fourth example - native german speaker speaking english in german accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"hui-berndungerer\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"de_DE\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{h ˈoː p ə} {j ˈuː} { ˈɑː r ə} { ˈɛ n j oː j ˌɪ ŋ} { ˈuː ɾ} {z ɛ s j ˈoː n} {z oː} {f ˈɑː ɾ!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7338838-186d-4dd9-b2e2-6c0f00adc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a109b1",
   "metadata": {},
   "source": [
    "## German-Native Speaker Speaking English in English Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb992e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth example - native german speaker speaking english in english accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"hui-berndungerer\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"en_US\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{h ˈoʊ p} {j uː} {ɑː ɹ} {ɛ n dʒ ˈɔɪ ɪ ŋ} {ˌaʊ ɚ} {s ˈɛ ʃ ə n} {s ˈoʊ} {f ˌɑːɹ!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023da68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a289757",
   "metadata": {},
   "source": [
    "## Spanish-Native Speaker Speaking English in Spanish Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28f108-7705-4ffc-b997-93c9845eaf88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fifth example - native spanish speaker speaking english in native accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"mailabs-tux\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"es_ES\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{ˈo p e} {ʝ ˈo w} {ˈa ɾ e} {e ŋ x ˈo j j i ŋ} {ˈo w ɾ} {s ˈe s s j o n} {s ˈo} {f ˈa ɾ!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885dfe3-a8ce-4675-b14f-a2cc1963db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294801e",
   "metadata": {},
   "source": [
    "## Spanish-Native Speaker Speaking English in English Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498eb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth example - native spanish speaker speaking english in native accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"mailabs-tux\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"en_US\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{h ˈoʊ p} {j uː} {ɑː ɹ} {ɛ n dʒ ˈɔɪ ɪ ŋ} {ˌaʊ ɚ} {s ˈɛ ʃ ə n} {s ˈoʊ} {f ˌɑːɹ!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35618a33",
   "metadata": {},
   "source": [
    "## French-Native Speaker Speaking English in French Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9166377-ba3d-4ad2-bb90-795127db977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sixth example - native french speaker speaking english in french accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"mailabs-nadineeckert\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"fr_FR\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{ ˈɔ p} { j ˈu} {ˈa ʁ} {(en) ɛ n dʒ ˈɔɪ ɪ ŋ (fr)} {ˈu ʁ} {s ɛ s j ˈɔ̃} {s ˈo} {f ˈa ʁ!}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6233d6-094c-4adb-b55d-cdba1aeffc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0e19d",
   "metadata": {},
   "source": [
    "## French-Native Speaker Speaking English in English Accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth example - native french speaker speaking english in french accent\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"mailabs-nadineeckert\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = \"en_US\"\n",
    "\n",
    "script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "\n",
    "print(\"Converted the sentence to phonemes: \", script)\n",
    "\n",
    "script = \"{h ˈoʊ p} {j uː} {ɑː ɹ} {ɛ n dʒ ˈɔɪ ɪ ŋ} {ˌaʊ ɚ} {s ˈɛ ʃ ə n} {s ˈoʊ} {f ˌɑːɹ!} {}\"\n",
    "\n",
    "output_file_path = run_inference(script=script, \n",
    "                                 speaker_id=speaker_id, \n",
    "                                 input_language_id=input_language_id, \n",
    "                                 target_accent_id=input_language_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7854a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74dd0f7-ce8c-41fe-b6c8-f08e30949bc9",
   "metadata": {},
   "source": [
    "## Optional utilities to visualize waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab5198-7102-458f-8bf2-82ad0e5e96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the output\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "x, sr = librosa.load(output_file_path)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387386fe-ad87-4791-9552-e40aaeff5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3733db2-79d5-4059-b546-2e24336bc725",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91defc0-a41c-4412-afeb-d823b0cffa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teardown datamodule\n",
    "data_module.teardown(stage=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486ee7d-b1e5-42f6-ae10-fc83506372bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up GPU memory\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88889e-c8e8-4e29-a8ed-7bfab10cd557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
