{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f8b490-bdbf-463a-9d2d-bf4669e0d41f",
   "metadata": {},
   "source": [
    "# Welcome to RAD-MMM inference tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c24bb3-4937-4068-bb1e-f7f6efd00370",
   "metadata": {},
   "source": [
    "Before we begin, please download the following dependencies:\n",
    "\n",
    "1. Language dictionaries from [here](https://drive.google.com/drive/folders/1woNCODwXh9aHu7Fd6b4Jo42aL7f5RFZg) and place them in `RAD-MMM/assets` folder.\n",
    "2. Download RAD-MMM checkpoint(s) and its config - [decoder.ckpt](https://drive.google.com/file/d/1ZLFHY5iSMdK852UwF1RqFr7cY2ejzeOw/view), [attribute_model.ckpt](https://drive.google.com/file/d/1EduYNwgtRlezJt6RiXMLBBSSOpIbp2CT/view?usp=sharing) and [config.yaml](https://drive.google.com/file/d/1c_dGA82k2Ow65P0vXwYwRTEipNdzTsTa/view?usp=sharing).\n",
    "3. Download HiFi-GAN vocoder checkpoint and its config - [g_00072000](https://drive.google.com/file/d/1VaH5_MhAjAjHlihi2k-lcOOoy4NqtRV4/view) and [config_16khz.json](https://drive.google.com/file/d/1-eBTNfIh-LSstNirQawHW4jsI-t01jTU/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('/akshit/scratch/RAD-MMM/vocoders')\n",
    "sys.path.append('/akshit/scratch/RAD-MMM')\n",
    "from pytorch_lightning.cli import LightningCLI\n",
    "from tts_lightning_modules import TTSModel\n",
    "from data_modules import BaseAudioDataModule\n",
    "from jsonargparse import lazy_instance\n",
    "from decoders import RADMMMFlow\n",
    "from loss import RADTTSLoss\n",
    "import inspect\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from training_callbacks import LogDecoderSamplesCallback, \\\n",
    "    LogAttributeSamplesCallback\n",
    "from utils import get_class_args\n",
    "from tts_text_processing.text_processing import TextProcessing\n",
    "from common import Encoder\n",
    "import torch\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for downloaded files\n",
    "attribute_model_path = \"../generator_ckpt/radmmm_public/attribute_model.ckpt\"\n",
    "gen_config_path = \"../generator_ckpt/radmmm_public/config.yaml\"\n",
    "decoder_model_path = \"../generator_ckpt/radmmm_public/decoder.ckpt\"\n",
    "voc_model_path = \"../generator_ckpt/hfg_public/g_00072000\"\n",
    "voc_config_path = \"../generator_ckpt/hfg_public/config_16khz.json\"\n",
    "phonemizer_cfg='{\"en_US\": \"assets/en_US_word_ipa_map.txt\",\"es_MX\": \"assets/es_MX_word_ipa_map.txt\",\"de_DE\": \"assets/de_DE_word_ipa_map.txt\",\"en_UK\": \"assets/en_UK_word_ipa_map.txt\",\"es_CO\": \"assets/es_CO_word_ipa_map.txt\",\"es_ES\": \"assets/es_ES_word_ipa_map.txt\",\"fr_FR\": \"assets/fr_FR_word_ipa_map.txt\",\"hi_HI\": \"assets/hi_HI_word_ipa_map.txt\",\"pt_BR\": \"assets/pt_BR_word_ipa_map.txt\",\"te_TE\": \"assets/te_TE_word_ipa_map.txt\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb91da-18c9-4014-933b-41d4e9278c5c",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edddca9-4d40-456e-9a80-cc438859255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config\n",
    "\n",
    "with open(gen_config_path, \"r\") as f:\n",
    "    gen_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86dbb4-be11-412b-979b-ad13ec9e52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_class(init):\n",
    "    \"\"\"Instantiates a class with the given args and init.\n",
    "\n",
    "    Args:\n",
    "        args: Positional arguments required for instantiation.\n",
    "        init: Dict of the form {\"class_path\":...,\"init_args\":...}.\n",
    "\n",
    "    Returns:\n",
    "        The instantiated class object.\n",
    "    \"\"\"\n",
    "    kwargs = init.get(\"init_args\", {})\n",
    "    class_module, class_name = init[\"class_path\"].rsplit(\".\", 1)\n",
    "    module = __import__(class_module, fromlist=[class_name])\n",
    "    args_class = getattr(module, class_name)\n",
    "    return args_class(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c16de-ca51-423f-a718-0a17ea93884b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate submodules\n",
    "\n",
    "gen_config[\"model\"][\"add_bos_eos_to_text\"] = False\n",
    "gen_config[\"model\"][\"append_space_to_text\"] = True\n",
    "gen_config[\"model\"][\"decoder_path\"] = decoder_model_path\n",
    "gen_config[\"model\"][\"encoders_path\"] = decoder_model_path\n",
    "gen_config[\"model\"][\"handle_phoneme\"] = \"word\"\n",
    "gen_config[\"model\"][\"handle_phoneme_ambiguous\"] = \"ignore\"\n",
    "gen_config[\"model\"][\"heteronyms_path\"] = \"tts_text_processing/heteronyms\"\n",
    "gen_config[\"model\"][\"output_directory\"] = \"tutorials/run1\"\n",
    "gen_config[\"model\"][\"p_phoneme\"] = 1\n",
    "gen_config[\"model\"][\"phoneme_dict_path\"] = \"tts_text_processing/cmudict-0.7b\"\n",
    "gen_config[\"model\"][\"phonemizer_cfg\"] = phonemizer_cfg\n",
    "gen_config[\"model\"][\"prediction_output_dir\"] = \"tutorials/out1\"\n",
    "gen_config[\"model\"][\"prepend_space_to_text\"] = True\n",
    "gen_config[\"model\"][\"sampling_rate\"] = 16000\n",
    "gen_config[\"model\"][\"symbol_set\"] = \"radmmm_phonemizer_marker_segregated\"\n",
    "gen_config[\"model\"][\"vocoder_checkpoint_path\"] = voc_model_path\n",
    "gen_config[\"model\"][\"vocoder_config_path\"] = voc_config_path\n",
    "\n",
    "hparams = gen_config[\"model\"]\n",
    "ttsmodel_kwargs={}\n",
    "for k,v in hparams.items():\n",
    "    if type(v) == dict and 'class_path' in v:\n",
    "        print(k)\n",
    "        ttsmodel_kwargs[k] = instantiate_class(v)\n",
    "    elif k != \"_instantiator\":\n",
    "        ttsmodel_kwargs[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c366d31-416e-4346-8589-0db6c8cfa2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the model from checkpoint\n",
    "model2 = TTSModel.load_from_checkpoint(checkpoint_path=attribute_model_path,\\\n",
    "                                      **ttsmodel_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dba2b0-0b78-4207-ba83-bd8914290850",
   "metadata": {},
   "source": [
    "## Initialize the datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bd7b8-01da-4c68-b214-2781a375033a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the datamodule\n",
    "\n",
    "gen_config[\"data\"][\"inference_transcript\"]=\"model_inputs/resynthesis_prompts.json\" #ToDo\n",
    "gen_config[\"data\"][\"batch_size\"]=1\n",
    "gen_config[\"data\"][\"phonemizer_cfg\"]=phonemizer_cfg\n",
    "data_module = BaseAudioDataModule(**gen_config['data'])\n",
    "data_module.setup(stage = \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7354be9-16b2-42d1-9603-efea292fc54c",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b11c0a-4507-4cda-a6d1-3538cba7f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the input through the model\n",
    "def run_inference(text, speaker_id, input_language_id, target_accent_id, script=None):\n",
    "    if script == None:\n",
    "        script = data_module.tp.convert_to_phoneme(text=text, phoneme_dict=data_module.tp.phonemizer_backend_dict[input_language_id])\n",
    "    print(\"Converted the text to phonemes: \", script)\n",
    "    inferData = [{\n",
    "      \"script\": script,\n",
    "      \"spk_id\": speaker_id,\n",
    "      \"decoder_spk_id\": speaker_id,\n",
    "      \"duration_spk_id\": speaker_id,\n",
    "      \"energy_spk_id\": speaker_id,\n",
    "      \"f0_spk_id\": speaker_id,\n",
    "      \"language\": target_accent_id,\n",
    "      \"emotion\": \"other\"\n",
    "    }]\n",
    "    \n",
    "    ## set predictset\n",
    "    data_module.predictset.data = inferData\n",
    "    \n",
    "    ## initialize and get the dataloader\n",
    "    dl = data_module.predict_dataloader()\n",
    "    \n",
    "    ## get the first input\n",
    "    inp1 = next(iter(dl))\n",
    "    \n",
    "    ## move the input tensors to GPU\n",
    "    for k in inp1.keys():\n",
    "        if type(inp1[k]) == torch.Tensor:\n",
    "            inp1[k] = inp1[k].to(device=\"cuda\")\n",
    "\n",
    "    return model2.forward(inp1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516a5f3-0ab1-4da8-bad0-5b40fbbb12de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first example - ljs (native english speaker) speaking en_US\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"ljs\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = input_language_id\n",
    "output_file_path = run_inference(text, speaker_id, input_language_id, target_accent_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b812b-c037-46a1-8b5a-fdb4273dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0dca5-fdd5-4a4f-92ab-504a1ce61038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first example with user-provided phonemes for fine-grained control over speech\n",
    "\n",
    "text = \"Hope you are enjoying our session so far!\"\n",
    "speaker_id = \"ljs\"\n",
    "input_language_id = \"en_US\"\n",
    "target_accent_id = input_language_id\n",
    "script=\"{h ˈoʊ p} {j uː} {ɑː ɹ} {ɛ n dʒ ˈɔɪ ɪ ŋ} {ˌaʊ ɚ} {s ˈɛ ʃ ə n} {s ˈoʊ} {f ˌɑːɹ!}\"\n",
    "output_file_path = run_inference(text, speaker_id, input_language_id, target_accent_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcdaa1f-f197-4071-a539-9871c98dc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535f9d4-d814-4208-80c6-767468c8c608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second example - native english speaker (ljs) speaking hindi\n",
    "\n",
    "text = \"आशा है कि आप अब तक हमारे सत्र का आनंद ले रहे हैं!\"\n",
    "speaker_id = \"ljs\"\n",
    "input_language_id = \"hi_HI\"\n",
    "target_accent_id = input_language_id\n",
    "output_file_path = run_inference(text, speaker_id, input_language_id, target_accent_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a85f05-1505-4ba2-a8eb-c76b63df246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f7a31-d7c8-4aad-b17d-c83d37fd3057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second example - with user-provided phonemes\n",
    "\n",
    "text = \"आशा है कि आप अब तक हमारे सत्र का आनंद ले रहे हैं!\"\n",
    "speaker_id = \"ljs\"\n",
    "input_language_id = \"hi_HI\"\n",
    "target_accent_id = input_language_id\n",
    "script=\"{ˈaː ʃ aː} {h ɛː} {k ˈɪ} {ˌaː p} {ˈʌ b} {t ˌə k} {h ə m ˌaː ɾ eː} {s ˈʌ t ɾ ə} {k aː} {aː n ˈʌ n d} {l ˈeː} {ɾ ˌə h eː} {h ɛ̃!}\"\n",
    "output_file_path = run_inference(text, speaker_id, input_language_id, target_accent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a7b67-e299-4bef-8e7d-89b09bfe600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3abaf-a683-4a8a-a368-9f7b7b4f3511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# third example - saying hindi in english accent\n",
    "\n",
    "text = \"आशा है कि आप अब तक हमारे सत्र का आनंद ले रहे हैं!\"\n",
    "speaker_id = \"ljs\"\n",
    "input_language_id = \"hi_HI\"\n",
    "target_accent_id = \"en_US\"\n",
    "\n",
    "output_file_path = run_inference(text, speaker_id, input_language_id, target_accent_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ed3bb-27b7-4ff6-8596-45dbfd8dcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab5198-7102-458f-8bf2-82ad0e5e96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the output\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "x, sr = librosa.load(output_file_path)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387386fe-ad87-4791-9552-e40aaeff5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3733db2-79d5-4059-b546-2e24336bc725",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91defc0-a41c-4412-afeb-d823b0cffa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teardown datamodule\n",
    "data_module.teardown(stage=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486ee7d-b1e5-42f6-ae10-fc83506372bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up GPU memory\n",
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88889e-c8e8-4e29-a8ed-7bfab10cd557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
